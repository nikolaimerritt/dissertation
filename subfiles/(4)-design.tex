\documentclass[../main.tex]{subfiles}
\begin{document}
\chapter{Design}
\section{Requirements Approach}
\subsection{Why a Language Server?}
When deciding what type of language extension to create, we surveyed a variety of options. 
\\
\\
The SWISH platform in which Logical English is currently edited is built on Codemirror, a JavaScript framework for creating web-based code editors. Thus writing the language server entirely in Codemirror was an obvious choice. However, at the time, the SWISH platform was written in Codemirror 5, but the maintainers were considering migrating to Codemirror 6. Prematurely writing the language extension in Codemirror 6 would be too much of a risk, as migration was uncertain, and users would not be able to test the extension until it was migrated. However, using Codemirror 5 would also have been a bad idea, as migration to Codemirror 6 would involve a large number of breaking changes \cite{codemirror_migration}, such as getting the position of text in a document, and making changes to the document, being entirely restructured.
\\ 
\\ 
This prompted us to then consider Monaco. \todo[inline]{Why were we considering Monaco? How would Monaco have worked with SWISH?}.
\\ 
\\ 
In the end, we found that what was really needed was an editor-agnostic language server. This meant that the single language server would be able to connect to any front-end that supports the Language Server Protocol. This includes online editors such as Codemirror 6 \cite{codemirror_6_language_server} and Monaco \cite{monaco_language_server}, along with some of the most popular desktop code editors: Visual Studio Code \cite{vsc_langserver_docs}, Visual Studio \cite{visual_studio_language_server} and IntelliJ \cite{intellij_language_server} \cite{ide_rankings}. Logical English is still in an early stage of development and adoption. Producing a language server would give the flexibility needed to branch out to all kinds of coding environments.

\subsection{Why a Visual Studio Code client?}
I had two requirements when searching for the right client for the language server. I was looking to maximise both the amount of features that the client supported, and the popularity of the language client. 
\\
\\
Surprisingly, the latter proved to be a lot easier to judge than the former. Stack Overflow, one of the most popular websites for the programming community, conducts global surveys every year monitoring the programming commnity's trends. In 2021, out of over 80,000 responses, Visual Studio Code had ``a significant lead as the Integrated Development Environment (IDE) of choice across all developers", with over 70\% of responders using the IDE  \cite{ide_rankings}. This made Visual Studio Code a clear choice in terms of popularity. 
\\
\\
However, I also considered two runner-up IDEs in the survey, Visual Studio and IntelliJ, with 29\% and 33\% of responders using the IDEs. As discussed earlier, all three IDEs support language servers. However, unlike Visual Studio Code, Visual Studio and IntelliJ are quite complex, heavyweight IDEs, both with much a larger application size, longer install time, and complex user interface. A large part of the target audience of Logical English are logicians and lawyers, neither of which are as a group familiar with enterprise programming. This lead me to decide that having to use an enterprise-programming IDE would be inconvenient and off-putting. 
\\
\\
Visual Studio Code has strong support for using language servers following the Language Server protocol. Although I could only truly verify this after having built a language server with a Visual Studio Code client, there were many indications of this that were available during my research. Microsoft's extensive documentation of the features available with a Visual Studio Code client, \cite{vsc_langserver_features}, along with the wide list of language servers built for Visual Studio Code \cite{open_source_language_servers} lead me to trust Visual Studio Code as a suitable language client. 
\todo[inline]{Pick a language server from the list and explain how it has all the required features.}


\subsection{Why a separate Syntax Highlighter?}
Although language servers can mark code for highlighting (and, indeed, mine does), it is common to delegate the majority of the highlighting to the client. This is done for efficiency reasons. The majority of syntactic highlighting does not require a complex algorithm to parse the document,: instead, it can be done through identifying parts of the document using regular expressions. Since it would be a waste of resources to communicate this computationally task to and from the client, this is done by the language client itself. This is done by a client reading a document that specifies the language's grammar, called the syntax highlighter.
%
%
%
\section{Technology Stack}
\subsection{Language Server}
Before any work could be done, I needed to decide on which technology stack to use. This was dictated mainly by the programming language involved. The following features were needed:
\\
\\
\textbf{Linux, Windows and Mac OS support} \\
The language server had to be able to connect to offline editors, and therefore run on user's desktops. This meant that the most up-to-date editions of the three most popular operating systems -- Linux, Windows and Mac OS X -- had to be supported.
\\
\\
\textbf{Support for strong typing} \\
Since creating a language server is a large and complex project, I needed to be using a langauge with strong typing in order to both avoid mistakes and receive context-aware support from my IDE.
\\
\\
\textbf{A Language Server Protocol API} \\
Writing Language Server Protocol requests manually would be inefficient, time-consuming and a potential cause of errors. A library that abstracted away the exact layout and content of Language Server Protocol requests would aid productivity.
\\ 
\\
These last two requirements only left two libraries: the \\ 
\texttt{Microsoft.VisualStudio.LanguageServer}, written for C\# \cite{visual_studio_language_server}, and \\ 
\texttt{vscode-languageserver}, written for TypeScript \cite{vsc_langserver_docs}. Since these language server libraries were both created by Microsoft \footnote{This should not be surprising, as Microsoft also created the Language Server Protocol.}, they are both structured quite similarly. 
\\
\\
In the end, the TypeScript library was chosen over the C\# library. Both libraries being quite similar, this decision was made because TypeScript was better suited for the task than C\#. The Language Server Protocol communicates using JSON, and it is easier to work with JSON in TypeScript rather than in C\#. Useful features include destructuring JSON, giving JSON objects unique types based on their fields, and treating JSON objects as implementing interfaces that have the same fields. This decision being made, the resulting technology stack was TypeScript, using \texttt{vscode-languageserver}, run locally using \codeword{Node.JS}. 

\subsection{The Syntax Highlighter}
Since the syntax highlighting is specified in a single JSON document, the technology stack required was minimal. Rather than writing the JSON document directly, I chose to write the TextMate grammar in a YAML document, from which the JSON document was then automatically generated using the command \codeword{yq} \cite{yq_repo}. This was done because of the length of the JSON required: YAML documents are easier to read due to their less cluttered syntax, with the scope of objects being determined by whitespace rather than brackets. Writing regular expressions is also easier in a YAML document. Regular expressions feature many backslashes: in JSON, unlike in YAML, these backslashes need to be escaped with another backslash. Regular expressions are confusing enough to read as they are -- I did not need any added confusion by having to parse escaped backslashes in my head!

\subsection{The Language Client}
Language servers written using the \texttt{vscode-languageserver} library connect seamlessly to visual studio code language clients written using the \texttt{vscode-languageclient} package. Thus, my main method of day-to-day testing was done using a local visual studio code client. I could be assured that all errors I found were due to the language server itself, not the connection, since the two libraries were built with each other in mind. 
%Tests were also done using a Codemirror 5 client that ran locally in the browser, to see which features carried over to Codemirror 5.
%
%
%
\section{Design Methodology}
The Language Client and Syntax Highlighter needed very little design. Hence the design discussed in this section will concern the syntax highlighter.

\subsection{Initial Design Methodology}
My initial design methodology was to have global variables which would store the document's current type hierarchy and current collection of templates. These two variables would be recalculated whenever the document received an update, and would be read, via a read-only view, whenever they were needed in semantic highlighting, auto-completion, error diagnosis and quick fix suggestions. 
\\
\\
On first consideration this seemed to be the most practical design. Re-calculating these two objects whenever the document received an update would ensure that these objects would only be re-calculated when necessary. Since reading the document and parsing its content was anticipated to be an expensive operation, ensuring that these operations only happened when necessary was anticipated to be important for performance. Further, using a read-only view to access these global objects should avoid bugs, even if the objects are accessed throughout the codebase.
\\
\\
However, once I had set up a language server with minimal examples of each type of feature, it was clear that this design approach would lead to concurrency issues. The server interacts with the document not through one signle entry point, but through multiple events: one event for each type of functionality. For example, a request for code completion could occur while the server is updating the list of templates. If the list of templates has not finished updating, this could lead to incorrect code completion.
\todo[inline]{Does the server run on a single thread? (Still an issue if code completion requested slightly before document update signal gets received). Or does each callback get run on its own thread?}
This was an issue that was thoroughly explored in the Operating Systems course. One solution that was taught was to use locks to ensure that the list of templates or type tree is not accessed halfway through being updated. However, this would not prevent the issue of (for example) the document's templates being updated, but a semanic highlighting request being received before the document update signal is received. 
\todo[inline]{Research more about this issue of on request being received before another. What is it called?}
\\
\\
The only way to avoid such an issue is for the templates and type tree to be updated every time before a request is processed. This way, the templates and type trees could now be local values to each request, and could even be made constant. Although this would result in duplicate work in the case that the document does not change between requests, this is the only way to avoid the above issue. This lead me to research design based around a lack of mutable state.

\subsection{Current Design Methodology}
The overall design methodology was mainly guided by the principles outlined in ``Java to Kotlin: A Refactoring Guidebook" by Duncan McGregor and Nat Pryce (first edition, published by O'Reily Media Incorporated). Although taking examples from refactoring Java code into Kotlin, the book outlined design principles based on the ideas of minimising mutable state in classes and using `pure', stateless functions. 
\\
\\
McGregor and Pryce give two relevant scenarios in which avoiding mutable state in classes and functions is benefitial. Firstly, stateless objects and functions (here, ``stateless" is shorthand for not having mutable state) do not change as their contents is iterated over, or otherwise accessed across multiple instructions. \cite{java_to_kotlin_stateless} This is exactly the solution that I was looking for in avoiding the first concurrency problem. Further, pure functions (for example, functions that operate on statelss objects) do not change their output if they are called multiple times\cite{java_to_kotlin_pure_functions}. This is ideal as (as discussed above) with each type of request now generating its own local type tree and list of templates, if the document has not changed between two requests, then the same templates and type tree should be produced. In other words, given the same document as input, the factory methods that generate the templates and type tree should produce the same output.
\\
\\
Another important reason for favouring minimal state programming is for ease of following the code. Limiting the use of global, mutable state in turn limits the scope for error. As put by McGregor and Pryce, when looking for the source of an error \cite{java_to_kotlin_error}, 
\begin{quote}
    If there is a possibility that a function could mutate shared state, we have to examine the source of the function and, recursively, every function that it calls, to understand what our system does. Every piece of global mutable state makes every function suspect.
\end{quote}
This principle extends even to beyond debugging errors. By the same principle, the greater the dependency on global, mutable state, the harder it is to reason about the code's behaviour. This is true both from a formal standpoint, and from a point of practical understanding. Limiting the scope of mutable state to local to a function, a \codeword{for} loop or an \codeword{if} statement, limits the effect the mutable state has, and therefore limits the complexity of the code.
\\
\\
This principle is especially important because of the time scope of this project. Despite being responsible for implementing working examples of the four kinds of features, the Logical English team may maintain and extend the editor once my work is complete. Therefore it is a priority that the editor's source code must be easy to understand, debug and improve on for an external team who had not been involved in its creation.
\end{document}